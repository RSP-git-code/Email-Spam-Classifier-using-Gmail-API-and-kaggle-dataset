{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3bb3ae1-9d21-4fbc-81ba-b18a9985df7d",
   "metadata": {},
   "source": [
    "# Email Spam Classifier Using Gmail and Kaggle Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecc62c4e-665c-4650-bad2-09dddabdcc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required libraries\n",
    "import os\n",
    "import base64\n",
    "import pickle\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72d43494-9255-40c2-a688-29e65555f049",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Authenticating with Gmail API\n",
      "INFO:googleapiclient.discovery_cache:file_cache is only supported with oauth2client<4.0.0\n",
      "INFO:root:Fetching emails from Gmail\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9573206876111441\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.95      1.00      0.98      1463\n",
      "        spam       1.00      0.68      0.81       224\n",
      "\n",
      "    accuracy                           0.96      1687\n",
      "   macro avg       0.98      0.84      0.89      1687\n",
      "weighted avg       0.96      0.96      0.95      1687\n",
      "\n",
      "Test Case 1:\n",
      "  Text: Your Amazon order has been shipped. Track your package here.\n",
      "  Prediction: ham\n",
      "  Spam Probability: 0.13\n",
      "Test Case 2:\n",
      "  Text: Win a free vacation to Maldives! Limited time offer.\n",
      "  Prediction: spam\n",
      "  Spam Probability: 0.45\n",
      "Test Case 3:\n",
      "  Text: Reminder: Your meeting with the professor is scheduled for tomorrow at 10 AM.\n",
      "  Prediction: ham\n",
      "  Spam Probability: 0.06\n",
      "Test Case 4:\n",
      "  Text: Your Account has been compromised click here for help!\n",
      "  Prediction: spam\n",
      "  Spam Probability: 0.17\n",
      "Test Case 5:\n",
      "  Text: Hey, can you send me the assignment file before class?\n",
      "  Prediction: ham\n",
      "  Spam Probability: 0.06\n"
     ]
    }
   ],
   "source": [
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# SCOPES for Gmail API\n",
    "SCOPES = ['https://www.googleapis.com/auth/gmail.readonly'] #Enable Api from Google developer console \n",
    "\n",
    "# Gmail Authentication is required of test subject for that you have to enter the given gmail id from which you want to read\n",
    "def authenticate_gmail():\n",
    "    logging.info(\"Authenticating with Gmail API\")\n",
    "    creds = None\n",
    "\n",
    "    # If corrupted token.pickle exists, delete it:this generally happens when the gmail  doesnt allow or has been error in authentication process\n",
    "    if os.path.exists('token.pickle'):\n",
    "        try:\n",
    "            with open('token.pickle', 'rb') as token:\n",
    "                creds = pickle.load(token)\n",
    "        except EOFError:\n",
    "            logging.warning(\"token.pickle is corrupted. Deleting and re-authenticating.\")\n",
    "            os.remove('token.pickle')\n",
    "            creds = None\n",
    "#If the given api credentials are invalid then  it will dump the token and refreshes it  so make sure to finish OAuth configuration to get proper credentials.json file\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file('credentials.json', SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        with open('token.pickle', 'wb') as token:\n",
    "            pickle.dump(creds, token)\n",
    "\n",
    "    service = build('gmail', 'v1', credentials=creds)\n",
    "    return service\n",
    "\n",
    "# Fetch emails from Gmail\n",
    "def fetch_gmail_data(service, max_results=50):\n",
    "    logging.info(\"Fetching emails from Gmail\")\n",
    "    results = service.users().messages().list(userId='me', maxResults=max_results).execute()\n",
    "    messages = results.get('messages', [])\n",
    "    snippets = []\n",
    "    for msg in messages:\n",
    "        msg_data = service.users().messages().get(userId='me', id=msg['id']).execute()\n",
    "        snippets.append(msg_data.get('snippet', ''))\n",
    "    return snippets\n",
    "\n",
    "# Preprocessing function:Removing unnecessary white space ,punctuations and other stuff\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Load static dataset\n",
    "mail_data_df = pd.read_csv(\"mail_data.csv\")\n",
    "mail_data_df = mail_data_df.rename(columns={'Message': 'Snippet'})\n",
    "mail_data_df['Cleaned_Snippet'] = mail_data_df['Snippet'].apply(preprocess_text)\n",
    "\n",
    "# Get Gmail data\n",
    "service = authenticate_gmail()\n",
    "gmail_snippets = fetch_gmail_data(service)\n",
    "gmail_df = pd.DataFrame({'Snippet': gmail_snippets})\n",
    "gmail_df['Category'] = 'ham'  # Labeling real-time messages as ham by default\n",
    "gmail_df['Cleaned_Snippet'] = gmail_df['Snippet'].apply(preprocess_text)\n",
    "\n",
    "# Combine both datasets: realtime data +kaggle dataset for gmail it is done to balance the dataset\n",
    "combined_df = pd.concat([mail_data_df, gmail_df], ignore_index=True)\n",
    "\n",
    "# Prepare data\n",
    "X = combined_df['Cleaned_Snippet']\n",
    "y = combined_df['Category'].astype(str)  # Ensure labels are strings\n",
    "\n",
    "# Train-Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# TF-IDF Vectorizer: converts text into numerical features using Bag of words model .it is refined  bag of words model\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.95)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Logistic Regression Model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, zero_division=0))\n",
    "def predict_spam(text, model, vectorizer, threshold=0.3):\n",
    "    \"\"\"\n",
    "    Predict whether a single email snippet is spam or not based on a threshold.\n",
    "    \n",
    "    Parameters:\n",
    "    - text: raw email snippet\n",
    "    - model: trained logistic regression model\n",
    "    - vectorizer: fitted TfidfVectorizer\n",
    "    - threshold: probability threshold for classifying as spam\n",
    "\n",
    "    Returns:\n",
    "    - prediction: 'spam' or 'ham'\n",
    "    - probability: spam probability score\n",
    "    \"\"\"\n",
    "    cleaned_text = preprocess_text(text)\n",
    "    vectorized_text = vectorizer.transform([cleaned_text])\n",
    "    prob = model.predict_proba(vectorized_text)[0][model.classes_.tolist().index('spam')]\n",
    "    \n",
    "    prediction = 'spam' if prob >= threshold else 'ham'\n",
    "    return prediction, prob\n",
    "test_cases = [\n",
    "    \"Your Amazon order has been shipped. Track your package here.\",\n",
    "    \"Win a free vacation to Maldives! Limited time offer.\",\n",
    "    \"Reminder: Your meeting with the professor is scheduled for tomorrow at 10 AM.\",\n",
    "    \"Your Account has been compromised click here for help!\",\n",
    "    \"Hey, can you send me the assignment file before class?\"\n",
    "]\n",
    "# takes index and test case by test case and checks if it is a spam or ham\n",
    "for i, email in enumerate(test_cases, 1):\n",
    "    prediction, probability = predict_spam(email, model, tfidf_vectorizer, threshold=0.15)\n",
    "    print(f\"Test Case {i}:\")\n",
    "    print(f\"  Text: {email}\")\n",
    "    print(f\"  Prediction: {prediction}\")\n",
    "    print(f\"  Spam Probability: {probability:.2f}\")\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518d0cd9-cb9a-422e-82ce-e1999bce0c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fddda6-30ac-49ef-a005-32ad5c4342d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df3c70e-9966-4946-afc7-5651c781589f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c250d71-2cad-4465-9889-de94da62165d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
